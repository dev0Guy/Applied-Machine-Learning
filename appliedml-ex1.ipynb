{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n!pip install dtreeviz\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport seaborn as sb\nimport random\n\nfrom dtreeviz.trees import *\n\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import preprocessing\nfrom sklearn.metrics import f1_score, accuracy_score, precision_score, roc_auc_score\nfrom sklearn import tree\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-10T14:23:14.030227Z","iopub.execute_input":"2022-06-10T14:23:14.032759Z","iopub.status.idle":"2022-06-10T14:23:23.789028Z","shell.execute_reply.started":"2022-06-10T14:23:14.032685Z","shell.execute_reply":"2022-06-10T14:23:23.787585Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"1. Upload data set\n2. data analysis\n3. clean the data\n4. feature selection\n5. \n ","metadata":{}},{"cell_type":"code","source":"my_data = pd.read_csv('../input/weather-dataset-rattle-package/weatherAUS.csv')\nmy_data.reset_index(drop=True, inplace=True)\n# my_data.drop(['Date'],inplace=True,axis=1)\nmy_data","metadata":{"execution":{"iopub.status.busy":"2022-06-10T14:23:23.792052Z","iopub.execute_input":"2022-06-10T14:23:23.792514Z","iopub.status.idle":"2022-06-10T14:23:24.702241Z","shell.execute_reply.started":"2022-06-10T14:23:23.792457Z","shell.execute_reply":"2022-06-10T14:23:24.701263Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"print(my_data.dtypes)\nmy_data.describe()","metadata":{"execution":{"iopub.status.busy":"2022-06-10T14:23:24.703976Z","iopub.execute_input":"2022-06-10T14:23:24.704996Z","iopub.status.idle":"2022-06-10T14:23:24.882078Z","shell.execute_reply.started":"2022-06-10T14:23:24.704935Z","shell.execute_reply":"2022-06-10T14:23:24.881016Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"print(\"number of missing values for each feature:\")\nprint(my_data.isna().sum())\nprint(\"\\nnumber of duplicate raws in the data set:\")\nprint(my_data.duplicated().sum())","metadata":{"execution":{"iopub.status.busy":"2022-06-10T14:23:24.884828Z","iopub.execute_input":"2022-06-10T14:23:24.885143Z","iopub.status.idle":"2022-06-10T14:23:25.249151Z","shell.execute_reply.started":"2022-06-10T14:23:24.885097Z","shell.execute_reply":"2022-06-10T14:23:25.247989Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"my_data.drop_duplicates(inplace=True)\nmy_data.dropna(inplace=True)\n\nprint(\"number of missing values for each feature:\")\nprint(my_data.isna().sum())\nprint(\"\\nnumber of duplicate raws in the data set:\")\nprint(my_data.duplicated().sum())\nmy_data.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-10T14:23:25.250645Z","iopub.execute_input":"2022-06-10T14:23:25.251389Z","iopub.status.idle":"2022-06-10T14:23:25.739294Z","shell.execute_reply.started":"2022-06-10T14:23:25.251346Z","shell.execute_reply":"2022-06-10T14:23:25.738053Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"my_data['Date'] = my_data['Date'].apply(lambda x: int(x.split('-')[1]))\nmy_data['Date']","metadata":{"execution":{"iopub.status.busy":"2022-06-10T14:23:25.741185Z","iopub.execute_input":"2022-06-10T14:23:25.741599Z","iopub.status.idle":"2022-06-10T14:23:25.819692Z","shell.execute_reply.started":"2022-06-10T14:23:25.741544Z","shell.execute_reply":"2022-06-10T14:23:25.818601Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"numerical= my_data.drop(['RainTomorrow'], axis=1).select_dtypes('number').columns\n\ncategorical = my_data.select_dtypes('object').columns\n\nprint(f'Numerical Columns:  {my_data[numerical].columns}')\nprint('\\n')\nprint(f'Categorical Columns: {my_data[categorical].columns}')","metadata":{"execution":{"iopub.status.busy":"2022-06-10T14:23:25.820976Z","iopub.execute_input":"2022-06-10T14:23:25.821228Z","iopub.status.idle":"2022-06-10T14:23:25.854853Z","shell.execute_reply.started":"2022-06-10T14:23:25.821198Z","shell.execute_reply":"2022-06-10T14:23:25.853773Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"pd.options.plotting.backend = \"plotly\"\nmy_data[numerical].plot(kind='hist')","metadata":{"execution":{"iopub.status.busy":"2022-06-10T14:23:25.856448Z","iopub.execute_input":"2022-06-10T14:23:25.857013Z","iopub.status.idle":"2022-06-10T14:23:32.878525Z","shell.execute_reply.started":"2022-06-10T14:23:25.856973Z","shell.execute_reply":"2022-06-10T14:23:32.877196Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"my_data[categorical].plot(kind='hist')","metadata":{"execution":{"iopub.status.busy":"2022-06-10T14:23:32.880388Z","iopub.execute_input":"2022-06-10T14:23:32.880673Z","iopub.status.idle":"2022-06-10T14:23:36.081506Z","shell.execute_reply.started":"2022-06-10T14:23:32.880639Z","shell.execute_reply":"2022-06-10T14:23:36.080161Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"#define number of rows and columns for subplots\nnrow=5\nncol=5\n\n# make a list of all dataframes \nfig, axes = plt.subplots(nrow, ncol)\nfig.set_size_inches(40, 40)\nfig.set_dpi(100)\n# columns= []\n# color_map = [[{i: random.random()} for i in range(33)] for j in range(12)]\n# my_colors = [(x/10.0, x/100.0, x/10.0) for x in range(10)]\n\nmy_colors = [ (random.random(),random.random(),0.75) for I  in range(100)]\n\n\n\n# plot counter\nfor inx,col in enumerate(my_data.columns):\n    axes[inx%nrow,inx//nrow].set_title(col)\n    axes[inx%nrow,inx//nrow].bar(my_data[col].unique(),height=my_data[col].value_counts(),color=my_colors)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-10T14:23:36.085927Z","iopub.execute_input":"2022-06-10T14:23:36.086273Z","iopub.status.idle":"2022-06-10T14:23:49.470336Z","shell.execute_reply.started":"2022-06-10T14:23:36.086231Z","shell.execute_reply":"2022-06-10T14:23:49.469588Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"male_heart = my_data[(my_data['RainTomorrow'] == 'Yes') & (my_data['RainToday'] == 'Yes')]['RainToday'].count()\nfemale_heart = my_data[(my_data['RainTomorrow'] == 'Yes') & (my_data['RainToday'] == 'No')]['RainToday'].count()\n\nmale_normal = my_data[(my_data['RainTomorrow'] != 'Yes') & (my_data['RainToday'] == 'Yes')]['RainToday'].count()\nfemale_normal = my_data[(my_data['RainTomorrow'] != 'Yes') & (my_data['RainToday'] == 'No')]['RainToday'].count()\n\n\nheart_df = pd.DataFrame({'RainTomorrow':[male_normal,male_heart],'RainToday':[0,1]})\nnorm_df = pd.DataFrame({'RainTomorrow':[female_normal,female_heart],'RainToday':[0,1]})\n\n\nheart = [male_heart,female_heart]\ntarget = [male_normal,female_normal]\nindex = ['Yes','No']\ndf = pd.DataFrame({'RainToday': target,\n                   'RainTomorrow': heart}, index=index)\n\ndf.plot.bar()\n","metadata":{"execution":{"iopub.status.busy":"2022-06-10T14:23:49.471505Z","iopub.execute_input":"2022-06-10T14:23:49.472227Z","iopub.status.idle":"2022-06-10T14:23:49.656781Z","shell.execute_reply.started":"2022-06-10T14:23:49.472190Z","shell.execute_reply":"2022-06-10T14:23:49.655848Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"fig=plt.figure(figsize=(20,8),facecolor='white')\n\nplt.suptitle('Relationship between continuous variables and one categorical variable',fontsize=\"xx-large\",fontweight=\"bold\")\n\ngs=fig.add_gridspec(1,2)\n\n\nax=[_ for i in range(2)]\n\nax[0]=fig.add_subplot(gs[0,0])\nax[1]=fig.add_subplot(gs[0,1])\n\n\nfor i in range(2):\n    ax[i].set_yticklabels([])\n    ax[i].tick_params(axis='y',length=0)\n    \n    for direction in [\"top\",\"right\", 'left']:\n        ax[i].spines[direction].set_visible(False)\n    \nsb.lineplot(data=my_data,x='Sunshine',y='Evaporation',ax=ax[0],hue='RainTomorrow')\nsb.scatterplot(data=my_data,x='Cloud3pm',y='Rainfall',hue='RainTomorrow',ax=ax[1],palette='viridis',markers='o',alpha=0.1)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-10T14:23:49.658621Z","iopub.execute_input":"2022-06-10T14:23:49.659357Z","iopub.status.idle":"2022-06-10T14:24:02.425783Z","shell.execute_reply.started":"2022-06-10T14:23:49.659292Z","shell.execute_reply":"2022-06-10T14:24:02.424643Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"my_data.rename(columns={'RainTomorrow':'Target'},inplace=True)\nmy_data","metadata":{"execution":{"iopub.status.busy":"2022-06-10T14:24:02.427627Z","iopub.execute_input":"2022-06-10T14:24:02.427917Z","iopub.status.idle":"2022-06-10T14:24:02.501756Z","shell.execute_reply.started":"2022-06-10T14:24:02.427881Z","shell.execute_reply":"2022-06-10T14:24:02.500801Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"le = preprocessing.LabelEncoder()\nfor col in my_data.columns:\n    if my_data[col].dtypes == object:\n        my_data[col] = le.fit_transform(my_data[col])\nmy_data","metadata":{"execution":{"iopub.status.busy":"2022-06-10T14:24:02.503052Z","iopub.execute_input":"2022-06-10T14:24:02.503325Z","iopub.status.idle":"2022-06-10T14:24:02.683285Z","shell.execute_reply.started":"2022-06-10T14:24:02.503277Z","shell.execute_reply":"2022-06-10T14:24:02.682297Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"\nfig, ax = plt.subplots(figsize=(20,20))\nmask = np.triu(np.ones_like(my_data.iloc[:,:-1].corr(), dtype=bool))\nsb.heatmap(my_data.iloc[:,:-1].corr(),mask=mask, annot=True, linewidths=.5, ax=ax)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-10T14:24:02.685087Z","iopub.execute_input":"2022-06-10T14:24:02.685491Z","iopub.status.idle":"2022-06-10T14:24:04.672932Z","shell.execute_reply.started":"2022-06-10T14:24:02.685449Z","shell.execute_reply":"2022-06-10T14:24:04.671852Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# corr = my_data.iloc[:,:-1].corr()\n# my_data.iloc[:,:-1].corr()[abs(corr)>=0.5]\n\n# Create correlation matrix\ncorr_matrix = corr = my_data.iloc[:,:-1].corr().abs()\n\n# Select upper triangle of correlation matrix\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n\n# Find features with correlation greater than 0.95\nto_drop = [column for column in upper.columns if any(upper[column] > 0.6)]\n\n\n# Drop features \nmy_data.drop(to_drop, axis=1, inplace=True)\nmy_data\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-10T14:24:04.674634Z","iopub.execute_input":"2022-06-10T14:24:04.674914Z","iopub.status.idle":"2022-06-10T14:24:04.819631Z","shell.execute_reply.started":"2022-06-10T14:24:04.674878Z","shell.execute_reply":"2022-06-10T14:24:04.817798Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12,12))\nsb.heatmap(my_data.corr()[:-1][['Target']].sort_values('Target').tail(11),\nvmax=1, vmin=-1, cmap='YlGnBu', annot=True, ax=ax);\nax.invert_yaxis()","metadata":{"execution":{"iopub.status.busy":"2022-06-10T14:24:04.821663Z","iopub.execute_input":"2022-06-10T14:24:04.822104Z","iopub.status.idle":"2022-06-10T14:24:05.276296Z","shell.execute_reply.started":"2022-06-10T14:24:04.822056Z","shell.execute_reply":"2022-06-10T14:24:05.274737Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"def get_mapper(model,X):\n    mapper = dict()\n    for key,val,_,_ in zip(X.columns[model.tree_.feature], model.tree_.threshold, \n                           model.tree_.children_left, model.tree_.children_right):\n        mapper[key]= val\n    return mapper","metadata":{"execution":{"iopub.status.busy":"2022-06-10T14:24:05.278331Z","iopub.execute_input":"2022-06-10T14:24:05.279026Z","iopub.status.idle":"2022-06-10T14:24:05.286500Z","shell.execute_reply.started":"2022-06-10T14:24:05.278972Z","shell.execute_reply":"2022-06-10T14:24:05.285066Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"def run__eval_models(my_data,split_size=50,max_depth=5):\n\n    #split between features and traget variables \n    X = my_data.iloc[:,:-1]\n    y = my_data.iloc[:,-1]\n\n    alpah_lst = np.arange(0.1,0.9,0.2)\n    iter_num = 1\n    model = DecisionTreeClassifier(criterion=\"gini\",splitter=\"best\",max_depth=max_depth,min_samples_split=split_size)\n\n\n    nrow=2\n    ncol=2\n\n    # make a list of all dataframes \n    fig, axes = plt.subplots(nrow, ncol)\n    fig.set_size_inches(18.5, 10.5)\n    fig.set_dpi(100)\n    columns= ['precision','accuracy','f1','RoC']\n\n\n    #Use Stratified K fold to split train-test data\n    for alpha in alpah_lst:\n\n        model_accuracy = []\n        model_precision = []\n        model_f1 = []\n        model_Roc = []\n\n\n        new_model_accuracy = []\n        new_model_precision = []\n        new_model_f1 = []\n        new_model_Roc = []\n        print(alpha)\n\n        skf = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n        for train_index, test_index in skf.split(X, y):\n            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n\n            model.fit(X_train,y_train)\n            y_pred = model.predict(X_test)\n            model_accuracy.append(accuracy_score( y_test,y_pred))\n            model_precision.append(precision_score(y_test, y_pred))\n            model_f1.append(f1_score(y_test,y_pred))\n            model_Roc.append(roc_auc_score(y_test,y_pred))\n\n\n            mapper = get_mapper(model,X_train)\n            y_pred = np.zeros((iter_num, *y_pred.shape))\n            for index in range(iter_num):\n                tmp = X_test.copy()\n                for r_idx,row in X_test.iterrows():\n                    for c_idx,feature_val in enumerate(row):\n                        feature = tmp.columns[c_idx]\n                        if feature in mapper and np.random.uniform(low=0.0, high=1.0, size=None) < alpha:\n                            if tmp.at[r_idx,feature] > mapper[feature]:\n                                tmp.at[r_idx,feature] = mapper[feature] * 1.01 if mapper[feature] < 0 else  mapper[feature] / 1.01\n                            else: \n                                tmp.at[r_idx,feature] = mapper[feature] / 1.01 if mapper[feature] < 0 else  mapper[feature] * 1.01\n                y_pred[index] = model.predict(tmp)\n            y_pred = np.median(y_pred,axis=0).astype(int)\n            new_model_accuracy.append(accuracy_score(y_test,y_pred))\n            new_model_precision.append(precision_score(y_test, y_pred))\n            new_model_f1.append(f1_score(y_test, y_pred))\n            new_model_Roc.append(roc_auc_score(y_test, y_pred))\n\n\n        axes[0,0].set_title('precision')\n        axes[0,0].plot(new_model_precision,'--',label=str(alpha))\n        axes[0,0].legend()\n\n        axes[0,1].set_title('accuracy')\n        axes[0,1].plot(new_model_accuracy,'--',label=str(alpha))\n        axes[0,1].legend()\n\n        axes[1,0].set_title('f1')\n        axes[1,0].plot(new_model_f1,'--',label=str(alpha))\n        axes[1,0].legend()\n\n        axes[1,1].set_title('Roc')\n        axes[1,1].plot(new_model_Roc,'--',label=str(alpha))\n        axes[1,1].legend()\n\n\n    #     #print(model_accuracy,model_precision)    \n    #     print(f\"mean accuracy: {np.asarray(model_accuracy).mean()}\")\n    #     print(f\"mean precision: {np.asarray(model_precision).mean()}\")\n    #     print(\"-\"*30)\n    #     #print(new_model_accuracy,new_model_precision)    \n    #     print(f\"mean accuracy: {np.asarray(new_model_accuracy).mean()}\")\n    #     print(f\"mean precision: {np.asarray(new_model_precision).mean()}\")\n    #     print(\"=\"*30)\n    #     print(model_accuracy)\n\n    axes[0,0].plot(model_precision)\n    axes[0,1].plot(model_accuracy)\n    axes[1,0].plot(model_f1)\n    axes[1,1].plot(model_Roc)\n    \n    return model\n","metadata":{"execution":{"iopub.status.busy":"2022-06-10T14:24:05.288374Z","iopub.execute_input":"2022-06-10T14:24:05.288770Z","iopub.status.idle":"2022-06-10T14:24:05.336460Z","shell.execute_reply.started":"2022-06-10T14:24:05.288711Z","shell.execute_reply":"2022-06-10T14:24:05.335393Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"np.random.seed(10)\nmodel = run__eval_models(my_data)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T14:24:05.338430Z","iopub.execute_input":"2022-06-10T14:24:05.338874Z","iopub.status.idle":"2022-06-10T14:24:47.997818Z","shell.execute_reply.started":"2022-06-10T14:24:05.338838Z","shell.execute_reply":"2022-06-10T14:24:47.996661Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"X = my_data.iloc[:,:-1]\ny = my_data.iloc[:,-1]\n\nviz = dtreeviz(model, X, y,\n                target_name=\"Target\",\n                feature_names=my_data.columns,\n                class_names=['0','1'])\n\nviz","metadata":{"execution":{"iopub.status.busy":"2022-06-10T14:24:47.999538Z","iopub.execute_input":"2022-06-10T14:24:47.999876Z","iopub.status.idle":"2022-06-10T14:25:07.977703Z","shell.execute_reply.started":"2022-06-10T14:24:47.999835Z","shell.execute_reply":"2022-06-10T14:25:07.976856Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# my_data.drop(['ever_married','gender','Residence_type'],inplace= True,axis=1)\n# np.random.seed(10)\n# model = run__eval_models(my_data)","metadata":{"execution":{"iopub.status.busy":"2022-06-10T14:25:07.978977Z","iopub.execute_input":"2022-06-10T14:25:07.979802Z","iopub.status.idle":"2022-06-10T14:25:07.983487Z","shell.execute_reply.started":"2022-06-10T14:25:07.979752Z","shell.execute_reply":"2022-06-10T14:25:07.982534Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}